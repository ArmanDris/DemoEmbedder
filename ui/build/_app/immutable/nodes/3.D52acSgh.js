import{s as c,n as t}from"../chunks/scheduler.mhZtr3qf.js";import{S as o,i as r,e as i,c as d,k as f,l as h,g as p,d as v}from"../chunks/index.By0cP33f.js";function b(a){let e,l=`<h1 class="svelte-1lf5kbn">Dataset &amp; Metrics</h1> <p class="svelte-1lf5kbn">This dataset is imbalanced, 22% of clients default while 78% do not. For
        this reason F1 score and Recall are the metrics we want to pay a lot of
        attention to. F1 score will give us a good indication of overall
        performance and Recall will tell us how well our model preforms when it
        sees the clients who do default.</p> <p class="svelte-1lf5kbn">The Kaggle page has descriptions for what values in the columns
        represent. <a href="https://www.kaggle.com/datasets/uciml/default-of-credit-card-clients-dataset" target="_blank" class="underline">Link to dataset.</a></p> <h1 class="svelte-1lf5kbn">Best Model</h1> <p class="svelte-1lf5kbn">I was able to get a test accuracy of 82% using CatBoost with
        hyperparameters I found using RandomizedSearch. The results were less
        than I expected since a dummy classifier scores 78%. Running
        RandomizedSearch on a more powerful computer would have probably allowed
        me to squeeze a few more points of accuracy. The overall f1, recall, and
        precision scores are good but when looking specifically at the default
        class they are very bad. It would be interesting to train a new model
        that sacrifices accuracy for recall in the DEFAULT class.</p> <table class="w-full"><tr><th class="svelte-1lf5kbn"></th><th class="svelte-1lf5kbn">precision</th><th class="svelte-1lf5kbn">recall</th><th class="svelte-1lf5kbn">f1-score</th></tr> <tr><td class="svelte-1lf5kbn">PAID</td><td class="svelte-1lf5kbn">0.84</td><td class="svelte-1lf5kbn">0.95</td><td class="svelte-1lf5kbn">0.89</td></tr> <tr><td class="svelte-1lf5kbn">DEFAULT</td><td class="svelte-1lf5kbn">0.68</td><td class="svelte-1lf5kbn">0.37</td><td class="svelte-1lf5kbn">0.48</td></tr> <tr><td class="svelte-1lf5kbn">average</td><td class="svelte-1lf5kbn">0.81</td><td class="svelte-1lf5kbn">0.82</td><td class="svelte-1lf5kbn">0.80</td></tr></table> <h1 class="svelte-1lf5kbn">All Models</h1> <h2 class="svelte-1lf5kbn">Linear Regression</h2> <p class="svelte-1lf5kbn">Train score: 0.810524, improved to 0.8106 with HPO <span class="text-[#859900]">(+0.000076)</span>.</p> <h2 class="svelte-1lf5kbn">SVC</h2> <p class="svelte-1lf5kbn">Train score: 0.8177, improved to 0.8183 with HPO <span class="text-[#859900]">(+0.0006)</span></p> <h2 class="svelte-1lf5kbn">Gradient Boosted Trees</h2> <p class="svelte-1lf5kbn">Train score: 0.8190, decreased to 0.8189 with HPO <span class="text-[#dc322f]">(-0.0001)</span></p> <h2 class="svelte-1lf5kbn">CatBoost</h2> <p class="svelte-1lf5kbn">Train score: 0.8175, improved to 0.8214 with HPO <span class="text-[#859900]">(+0.0039)</span></p>`;return{c(){e=i("div"),e.innerHTML=l,this.h()},l(s){e=d(s,"DIV",{class:!0,"data-svelte-h":!0}),f(e)!=="svelte-aygxv6"&&(e.innerHTML=l),this.h()},h(){h(e,"class","w-[50%] mt-16 mx-auto")},m(s,n){p(s,e,n)},p:t,i:t,o:t,d(s){s&&v(e)}}}class m extends o{constructor(e){super(),r(this,e,null,b,c,{})}}export{m as component};
